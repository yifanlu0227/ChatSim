scene_name: &scene_name segment-11379226583756500423_6230_810_6250_810_with_camera_labels # scene name, corresponding to tfrecord's name

scene:
  data_root: data/waymo_multi_view # root directory of the dataset
  scene_name: *scene_name
  
  # suppose these files are under $data_root/$scene_name/ 
  ext_int_file: 'cams_meta.npy'       # extrinsic and intrinsic parameters
  bbox_file: '3d_boxes.npy'           # 3d bounding boxes
  map_file: 'map.pkl'                 # map file
  init_img_file: 'wide_init_img.png'  # initial image. Automatically generated if not exists. Should be different if `is_wide_angle` is different
  pcd_file: 'point_cloud/000_TOP.ply' # first frame's point cloud file

  is_wide_angle: &is_wide_angle true  # whether rendering wide angle images (Width -> 3x Width)
  frames: 50                          # number of frames to render
  fps: 5                             # fps of the output video
  multi_process_num: 5                       # multiple process num of foreground rendering
  if_with_depth: false                # whether the foreground rendering process considering depth and occlusion
  if_backup: true                    # whether save the backup files for foreground rendering debugging(HDRI, images, depth)

  # under root directory
  cache_dir: 'results/cache'          # cache directory
  output_dir: 'results'               # output directory
  save_cache: true                    # whether to save cache

agents:
  asset_select_agent:
    assets_dir: data/blender_assets   # directory of 3D assets

  background_rendering_agent:
    nerf_config: &nerf_config
      is_wide_angle: *is_wide_angle
      scene_name: *scene_name
      f2nerf_dir: chatsim/background/mcnerf         # directory of mcnerf (mcnerf uses f2nerf as the backbone)
      nerf_exp_name: exp_coeff_0.3                  # experiment name, corresponding to your trained model
      rendering_mode: render_wide_angle_hdr_shutter # `render_wide_angle_hdr_shutter` if `is_wide_angle` is true, otherwise `render_hdr_shutter`

      f2nerf_config: wanjinyou_big                  # f2nerf config name
      dataset_name: waymo_multi_view                # dataset name

      nerf_quiet_render: false                      # whether to suppress nerf's output in the terminal

  deletion_agent:
    inpaint_dir: chatsim/background/latent-diffusion          # directory of latent diffusion
    video_inpaint_dir: chatsim/background/Inpaint-Anything    # directory of inpaint-anything

  foreground_rendering_agent:
    nerf_config: *nerf_config

    skydome_hdri_dir: data/waymo_skydome                    # directory of skydome hdri
    skydome_hdri_idx: '033'                                 # manually select the best estimated skydome hdri 

    # whether to use surrounding lighting 
    # Currently `use_surrounding_lighting` only takes effect when merely one vehicle is added,
    # because in Blender, HDRI is a global illumination, and it is difficult to set a separate HDRI for each car.

    # It can be extremely slow when `use_surrounding_lighting` is true 
    # because it calls nerf rendering each frame.
    use_surrounding_lighting: false                  

    blender_dir: chatsim/foreground/Blender/blender-3.5.1-linux-x64/blender  # directory of blender
    blender_utils_dir: chatsim/foreground/Blender/utils/blender_utils               # directory of blender utils

    estimate_depth: false                                   # whether to estimate depth
    depth_est:
      method: SAM
      SAM:
        ckpt: &sam_ckpt data/pretrain/sam_vit_h_4b8939.pth
        model_type: vit_h

  project_manager:
    none

  motion_agent: 
    motion_tracking: true                                   # whether to use tracking module
  
  view_adjust_agent:
    none