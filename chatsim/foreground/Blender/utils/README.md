# BlenderUtils
This repo provides a CLI tool for Blender rendering without opening Blender GUI.

Suppose you have already finished the **Step 4** in the ChatSim's README.

### Make a softlink to assets
```bash
ln -s ../../../../data/blender_assets assets
```

### Edit ~/.bashrc to create a shortcut
```bash
vim ~/.bashrc

# add the following line to ~/.bashrc
alias blender=<ChatSim_project>/chatsim/foreground/Blender/blender-3.5.1-linux-x64/blender
```
note that `<ChatSim_project>` is where you clone the ChatSim repo. 

## Usage 
### Virtual Object Insertion
Look at the yaml files in `<ChatSim_project>/chatsim/foreground/Blender/utils/config`, for example:
``` yaml
# name for this rendering pass, also the name of output folder
render_name: multi_demo_1346
# name of output directory
output_dir: /home/yfl/workspace/BlenderUtils/output

# path to scene file.
scene_file: "/home/yfl/blender/waymo_sunny/segment-13469905891836363794_4429_660_4449_660_with_camera_labels/data.npz"
# start with an empty scene
blender_file: None
# Path to environment HDRI file. It is supposed to be generated by the lighting estimation algorithm. 
hdri_file: /home/yfl/workspace/dataset_ln/HDR_ours/train/abandoned_parking_1k.exr

# cars are stored in the list
cars: 
  - new_obj_name: chevrolet1 # should be different across each instance

    # blender model file path
    blender_file: /home/yfl/workspace/BlenderUtils/assets/chevrolet-suv-rigged.blend

    # inserting position of the virtual object. Coordinate follows the scene_file.
    insert_pos:
      - 37
      - 7
      - 0

    # inserting heading of the virtual object. Coordinate follows the scene_file. Radians.
    insert_rot: # rad
      - 1.5708  # model-specfic
      - 0       # model-specfic
      - 0       # car heading.

    # object name within blender_file, always "Car"
    model_obj_name: Car 

    # Optional. You can change the color of the car painting.
    # If added, it will change the car body's color to the given color.
    # material_key is always 'car_paint'
    target_color: 
      material_key: car_paint # always car_paint
      color: [0.2, 0.85, 0.05, 1]
    
  - new_obj_name: range_rover1
    blender_file: /home/yfl/workspace/BlenderUtils/assets/Range_Rover_Sports_2018.blend
    insert_pos:
      - 30.6
      - 10
      - 0
    insert_rot: 
      - 0
      - 0
      - 0
    model_obj_name: Car 
    target_color: 
      material_key: car_paint
      color: [0.9, 0.05, 0.05, 1]
  
  - ...
```

### Explanation of scene_file
It is stored in a npz file, and should include keys like:

- H: Height of rendered image. The same as height of images in the dataset. e.g. 1280 for waymo
- W: Width of rendered image. The same as Width of images in the dataset. e.g. 1920 for waymo
- focal: Focal length in unit of pixel.
- rgb: The background image of virutal object insertion. np.ndarray with dtype=int8, shape=[H, W, 3]. Can be rendered results from NeRF.
- depth: The depth of background. np.ndarray with dtype=float32, shape=[H, W]. Can be rendered results from NeRF.
- extrinsic: camera2world transformation matrix, corresponding to this background image. np.ndarray with dtype=float32, shape=[4, 4]. OpenCV camera coordinate (RDF). Also the pose of camera in world coordinate.

### Usage
Once you have the yaml and the scene/blender/hdri files needed inside the yaml. You can render the results with:
```bash
blender -b --python blender_utils/main_multicar.py -- config/Wide_angle_test -- 0 -- 1 
```
The last two arguments refers to start and end frame index. Since we only have one frame (one yaml) in this demo, we set them to 0 and 1.

In the output folder, you will see the following complete result when `depth_and_occlusion` is enabled.
```
├── backup
│   ├── hdri.exr
│   └── RGB.png
├── depth
│   └── vehicle_and_plane0001.exr
├── label.yaml
├── mask
│   └── vehicle_and_shadow0001.exr
├── RGB
│   └── vehicle_and_shadow_over_background0001.png
├── RGB_composite.png
└── RGB_over_background.png
```

`RGB_composite.png` is the final inserted result.

### Special Explantation for Extrinsic in scene_file
![camera_coord](imgs/camera_coord.webp "camera_coord")

OpenCV camera coordinate: **RDF**

Blender camera coordinate: **RUB**

We suppose the extrinsic follows **OpenCV camera coordinate**. It will be transformed to Blender camera coordiniate automatically in the `get_rotation_quaternion` function in `blender_utils/camera/set_camera.py`. *But which is the most convenient camera coordinate system for you guys? Please let me know.*

For example, the waymo scene 1346, camera trajectory is as follows: 

| ![1346-0](imgs/1346-0.png)| ![1346-1](imgs/1346-1.jpg) | ![1346-2](imgs/1346-2.jpg) |
| -------------------------------------------- | -------------------------------------------- | -------------------------------------------- |

Note the world coordinate (the big box) and the OpenCV camera coordinate (the small axis) in **RDF**.

Now have a look at the camera transformed into blender camera coordinate system in **RUB**. For example, the waymo scene 1024:

![1024-blender](imgs/1024-blender.png)


### Sync 3D Assets
stored in 303A PC /home/yfl/workspace/BlenderUtils/assets

In 303A PC's terminal, use scp to upload these files:
```
scp -r /home/yfl/workspace/BlenderUtils/assets <HPC username>@sydata.hpc.sjtu.edu.cn:<BlenderUtils PATH in HPC>
```
